{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb5bff3-6724-402d-9faa-86078f602b71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec61d6d-ea1a-4d2f-9ee6-625393a24aa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f67ffe-ad1b-49a1-a7cf-603daa8c9890",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load data\n",
    "The tutorial uses a dataset describing different wine samples. The [dataset](https://archive.ics.uci.edu/ml/datasets/Wine) is from the UCI Machine Learning Repository and is included in DBFS ([AWS](https://docs.databricks.com/data/databricks-file-system.html)|[Azure](https://docs.microsoft.com/azure/databricks/data/databricks-file-system)|[GCP](https://docs.gcp.databricks.com/data/databricks-file-system.html)).\n",
    "The goal is to classify red and white wines by their quality. \n",
    "\n",
    "For more details on uploading and loading from other data sources, see the documentation on working with data ([AWS](https://docs.databricks.com/data/index.html)|[Azure](https://docs.microsoft.com/azure/databricks/data/index)|[GCP](https://docs.gcp.databricks.com/data/index.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51fd8a9f-bef3-4fbd-90ce-8531f5f71205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "\n",
    "\n",
    "# File location and type\n",
    "file_location = \"/FileStore/tables/winequality_whites.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \";\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "white_wine = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "# File location and type\n",
    "file_location = \"/FileStore/tables/winequality_reds.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \";\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "red_wine = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "display(white_wine)\n",
    "display(red_wine)\n",
    "\n",
    "white_wine = white_wine.toPandas()\n",
    "red_wine = red_wine.toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe3fe69-4b4d-4a56-86a8-38f1f42ec564",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#white_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-white.csv\", sep=';')\n",
    "#red_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-red.csv\", sep=';')\n",
    "white_wine['is_red'] = 0.0\n",
    "red_wine['is_red'] = 1.0\n",
    "data_df = pd.concat([white_wine, red_wine], axis=0)\n",
    "\n",
    "# Define classification labels based on the wine quality\n",
    "data_labels = data_df['quality'].astype(int) >= 7\n",
    "data_df = data_df.drop(['quality'], axis=1)\n",
    "\n",
    "# Split 80/20 train-test\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "  data_df,\n",
    "  data_labels,\n",
    "  test_size=0.2,\n",
    "  random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8123df40-67fa-43d0-97c1-6f608c9f7d61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 1. Train a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e0381e-7c02-4e57-b29b-127a7585992b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable MLflow autologging for this notebook\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70fefb47-9af8-49c8-932d-49a0727c1428",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='gradient_boost') as run:\n",
    "  model = sklearn.ensemble.GradientBoostingClassifier(random_state=0)\n",
    "  \n",
    "  # Models, parameters, and training metrics are tracked automatically\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  predicted_probs = model.predict_proba(X_test)\n",
    "  roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "  \n",
    "  # The AUC score on test data is not automatically logged, so log it manually\n",
    "  mlflow.log_metric(\"test_auc\", roc_auc)\n",
    "  print(\"Test AUC of: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06eadee7-a786-4a6a-be73-c70a7c18c0a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "If you aren't happy with the performance of this model, train another model with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85fa6e22-56ab-44da-89c0-e77f883c5fcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start a new run and assign a run_name for future reference\n",
    "with mlflow.start_run(run_name='gradient_boost') as run:\n",
    "  model_2 = sklearn.ensemble.GradientBoostingClassifier(\n",
    "    random_state=0, \n",
    "    \n",
    "    # Try a new parameter setting for n_estimators\n",
    "    n_estimators=200,\n",
    "  )\n",
    "  model_2.fit(X_train, y_train)\n",
    "\n",
    "  predicted_probs = model_2.predict_proba(X_test)\n",
    "  roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "  mlflow.log_metric(\"test_auc\", roc_auc)\n",
    "  print(\"Test AUC of: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d85461a-9f6d-43e4-abb5-0d72e1fe48a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# After a model has been logged, you can load it in different notebooks or jobs\n",
    "# mlflow.pyfunc.load_model makes model prediction available under a common API\n",
    "model_loaded = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=run.info.run_id\n",
    "  )\n",
    ")\n",
    "\n",
    "predictions_loaded = model_loaded.predict(X_test)\n",
    "predictions_original = model_2.predict(X_test)\n",
    "\n",
    "# The loaded model should match the original\n",
    "assert(np.array_equal(predictions_loaded, predictions_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eaefdfe-f00e-4e3b-b647-4ed56cb89b15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 2. Hyperparameter Tuning\n",
    "At this point, you have trained a simple model and used the MLflow tracking service to organize your work. This section covers how to perform more sophisticated tuning using Hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3f22d5-8217-42ad-bd78-fbf30ef5538c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space to explore\n",
    "search_space = {\n",
    "  'n_estimators': scope.int(hp.quniform('n_estimators', 20, 1000, 1)),\n",
    "  'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "  'max_depth': scope.int(hp.quniform('max_depth', 2, 5, 1)),\n",
    "}\n",
    "\n",
    "def train_model(params):\n",
    "  # Enable autologging on each worker\n",
    "  mlflow.autolog()\n",
    "  with mlflow.start_run(nested=True):\n",
    "    model_hp = sklearn.ensemble.GradientBoostingClassifier(\n",
    "      random_state=0,\n",
    "      **params\n",
    "    )\n",
    "    model_hp.fit(X_train, y_train)\n",
    "    predicted_probs = model_hp.predict_proba(X_test)\n",
    "    # Tune based on the test AUC\n",
    "    # In production settings, you could use a separate validation set instead\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "    mlflow.log_metric('test_auc', roc_auc)\n",
    "    \n",
    "    # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "    return {'status': STATUS_OK, 'loss': -1*roc_auc}\n",
    "\n",
    "# SparkTrials distributes the tuning using Spark workers\n",
    "# Greater parallelism speeds processing, but each hyperparameter trial has less information from other trials\n",
    "# On smaller clusters or Databricks Community Edition try setting parallelism=2\n",
    "spark_trials = SparkTrials(\n",
    "  parallelism=2\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name='gb_hyperopt') as run:\n",
    "  # Use hyperopt to find the parameters yielding the highest AUC\n",
    "  best_params = fmin(\n",
    "    fn=train_model, \n",
    "    space=search_space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=32,\n",
    "    trials=spark_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae7ad39-0eea-4dcd-a58a-dcfc723ba91f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Search runs to retrieve the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ea75b75-0439-4fa2-9f8c-6bbd2b586719",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort runs by their test auc; in case of ties, use the most recent run\n",
    "best_run = mlflow.search_runs(\n",
    "  order_by=['metrics.test_auc DESC', 'start_time DESC'],\n",
    "  max_results=10,\n",
    ").iloc[0]\n",
    "print('Best Run')\n",
    "print('AUC: {}'.format(best_run[\"metrics.test_auc\"]))\n",
    "print('Num Estimators: {}'.format(best_run[\"params.n_estimators\"]))\n",
    "print('Max Depth: {}'.format(best_run[\"params.max_depth\"]))\n",
    "print('Learning Rate: {}'.format(best_run[\"params.learning_rate\"]))\n",
    "\n",
    "best_model_pyfunc = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=best_run.run_id\n",
    "  )\n",
    ")\n",
    "best_model_predictions = best_model_pyfunc.predict(X_test[:5])\n",
    "print(\"Test Predictions: {}\".format(best_model_predictions))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Nitin_train",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
